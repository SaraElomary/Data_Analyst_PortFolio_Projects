# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10zgKtLoYsP_rlWJFajnT0bz1SVBb_PxD
"""

import pandas as pd 
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns

# import data
df = pd.read_csv('/content/drive/My Drive/dataset.csv',delimiter=';')
df.head(n=8)

"""Correlation between numerical variables"""

df.info()

columns_name = ['Division', 'Magasin', 'Date pièce', 'Date comptable', 'Article',
                'Designation article', 'Prix moyen Pondere', 'Document article',
                 'Qte en unite saisie' , 'Qte en UL', 'Qte en UL periode precedente',
               'Motif du mouvement', 'Code mouvement', 'Montant', 'Date de saisie',
                'Type d\'approvisionnement',
               'Niveau de qualite de l’eau', 'Temperature', 'Pollution', 'Humidite']
    
df = df.drop('Code blocage inventaire',axis=1)
df = df.drop('Unite de stock',axis=1)
df = df.drop('Periode d\'achat',axis=1)
df = df.drop('Date limite de consommation/peremption',axis=1)
df = df.drop('Type d\'approvisionnement',axis=1)

df.columns

df['Date pièce'] = pd.to_datetime(df['Date pièce'])
df['Date comptable'] = pd.to_datetime(df['Date comptable'])
df['Date de saisie'] = pd.to_datetime(df['Date de saisie'])
df['Date pièce'] = pd.to_datetime(df["Date pièce"])

# objects datatypes  to numbers
df['Prix moyen Pondere'] = pd.to_numeric(df['Prix moyen Pondere'])
df['Qte en unite saisie']= pd.to_numeric(df['Qte en unite saisie'])
df['Qte en UL'] = pd.to_numeric(df['Qte en UL'])
df['Qte en UL periode precedente '] = pd.to_numeric(df['Qte en UL periode precedente '])
df['Montant '] = pd.to_numeric(df['Montant '])

#format 
df['Qte en unite saisie']=df['Qte en unite saisie'].str.replace(' ', '')
df['Qte en unite saisie']=df['Qte en unite saisie'].str.replace(',', '.')
df['Qte en UL']=df['Qte en UL'].str.replace(',', '.')
df['Qte en UL periode precedente ']=df['Qte en UL periode precedente '].str.replace(',', '.')
df['Montant ']=df['Montant '].str.replace(' ', '')
df['Montant ']=df['Montant '].str.replace(',', '.')
df['Prix moyen Pondere'] = df['Prix moyen Pondere'].str.replace(',', '.')
df['Qte en UL']=df['Qte en UL'].str.replace(' ', '')
df['Qte en UL periode precedente ']=df['Qte en UL periode precedente '].str.replace(' ', '')

import pandas as pd 
import matplotlib.pyplot as plt

correlation = df.corr()
plt.figure(figsize=(10,10))
sns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')

df.corr()

df.columns

df['Magasin'] = df.fillna(df['Magasin'].value_counts().index[0]) 
df['Montant '] = df['Montant '].replace(np.NaN, df['Montant '].mean())

X = df[['Article','Prix moyen Pondere','Document article','Qte en UL','Qte en UL periode precedente ','Motif du mouvement', 'Code mouvement', 'Montant ']]
y = df['Qte en unite saisie']
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X = sc.fit_transform(X)
y = sc.fit_transform(y.values.reshape(-1,1))

from sklearn.decomposition import PCA
#PCA
pca = PCA(n_components=2)
pcax = pca.fit_transform(X,y)
pca.explained_variance_ratio_

#LDA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis()
X_lda = lda.fit_transform(X, y)

explained_variance = pca.explained_variance_ratio_
print(explained_variance)

df.columns

import prince
newMain = df[['Division','Magasin','Designation article' ,'Niveau de qualite de l’eau ','Temperature ', 'Pollution', 'Humidite']]
mca = prince.MCA(
    n_components=2,
    random_state=0,
    n_iter=1
)
main_mca = mca.fit_transform(newMain)
print(main_mca)

A =pd.DataFrame(main_mca)
B = pd.DataFrame(pcax)
DFT = pd.concat([A, B], axis=1)
print(DFT)

X_train, X_test, y_train, y_test = train_test_split(DFT, y, random_state=1)

from sklearn.ensemble import RandomForestRegressor
# Instantiate model with ** decision trees
rf = RandomForestRegressor(n_estimators = 800, random_state = 65)
#rf = RandomForestRegressor()

# Train the model on training data
rf.fit(X_train, y_train)

X_test.shape

predictions = rf.predict(X_test)

dfForest = pd.DataFrame({'Actual values': y_test, 'Predicted values': predictions})
dfForest

from sklearn.tree import DecisionTreeRegressor  
from sklearn.metrics import f1_score, confusion_matrix, classification_report
from sklearn.model_selection import learning_curve
# create a regressor object 
#regressorTree = DecisionTreeRegressor(max_depth=2, min_samples_leaf = 0.2, random_state = 0)  
regressorTree = DecisionTreeRegressor()  
regfit = regressorTree.fit(X_train, y_train)

# fit the regressor with X and Y data 
prdction = regressorTree.predict(X_test) 
dfForest = pd.DataFrame({'Actual values': y_test, 'Predicted values': prdction})
dfForest

from sklearn import metrics

print('Mean Squared Error:', metrics.mean_squared_error(y_test, prdction))

from sklearn.linear_model import Ridge 
# training model with 0.5 alpha value 
#model = Ridge() 
model = Ridge( alpha = 0.1, normalize = False, tol = 0.001,
              solver ='auto', random_state = 42) 

model.fit(X_train, y_train)

prd = model.predict(X_test) 
p = pd.DataFrame({'Actual values': y_test, 'Predicted values': prd})
p

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import ElasticNet
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
elastic=ElasticNet(normalize=True)
search=GridSearchCV(estimator=elastic,param_grid={'alpha':np.logspace(-5,2,8),
                                                  'l1_ratio':[.2,.4,.6,.8]},scoring=
                    'neg_mean_squared_error',n_jobs=1,refit=True,cv=10)
search.fit(X_train,y_train)
search.best_params_

elastic=ElasticNet(normalize=True,alpha=0.001,l1_ratio=0.3)
elastic.fit(X_train,y_train)
second_model=(mean_squared_error(y_true=y_test,y_pred=elastic.predict(X_test)))
print(second_model)
